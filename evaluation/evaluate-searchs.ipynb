{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gary/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-09-15 17:02:56.472818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-15 17:02:56.492706: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-15 17:02:56.492738: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-15 17:02:56.506051: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-15 17:02:57.342941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "with open('fixed_ground_truth.pkl','rb') as infile:\n",
    "    data = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)\n",
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data = []\n",
    "for i in data:\n",
    "    d = {}\n",
    "    d['title'] = i['title']\n",
    "    d['text'] = i['text']\n",
    "    d['timecode_text'] = i['timecode_text']\n",
    "    d['description'] = i['description']\n",
    "    d['id'] = i['id']\n",
    "    d['text_vector'] = model.encode(i['title']+' '+i['text']+' '+i['description'])\n",
    "    vector_data.append(d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in data:\n",
    "    if i['id']:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_data[0]['text_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'vector-search'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"timecode_text\": {\"type\": \"text\"},\n",
    "            \"description\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "index_name = \"vector-search\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in vector_data:\n",
    "    try:\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_query(question):\n",
    "    return  {\n",
    "        \"field\": \"text_vector\",\n",
    "        \"query_vector\": model.encode(question),\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5,\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did we talk about Mage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(question):\n",
    "    res = es_client.search(index=index_name, knn=knn_query(question), source=[\"id\"])\n",
    "    return res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'vector-search',\n",
       "  '_id': 'e0TL95EB5LG_H-Mr0L4B',\n",
       "  '_score': 0.29429528,\n",
       "  '_source': {'id': '5c9135a7b0adea3271a398bf9c80fc91'}},\n",
       " {'_index': 'vector-search',\n",
       "  '_id': 'fETL95EB5LG_H-Mr0L4F',\n",
       "  '_score': 0.29429528,\n",
       "  '_source': {'id': '5c9135a7b0adea3271a398bf9c80fc91'}},\n",
       " {'_index': 'vector-search',\n",
       "  '_id': 'fUTL95EB5LG_H-Mr0L4J',\n",
       "  '_score': 0.29429528,\n",
       "  '_source': {'id': '5c9135a7b0adea3271a398bf9c80fc91'}},\n",
       " {'_index': 'vector-search',\n",
       "  '_id': 'RkTL95EB5LG_H-Mry71B',\n",
       "  '_score': 0.28033978,\n",
       "  '_source': {'id': '3cba0dbf73297ec686a5b91511d47dbe'}},\n",
       " {'_index': 'vector-search',\n",
       "  '_id': 'R0TL95EB5LG_H-Mry71F',\n",
       "  '_score': 0.28033978,\n",
       "  '_source': {'id': '3cba0dbf73297ec686a5b91511d47dbe'}}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e884a810824b93af5c99069cfa73d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "relevance_total = []\n",
    "for q in tqdm(data):\n",
    "    doc_id = q['id']\n",
    "    results = vector_search(q['student_question'])\n",
    "    relevance = [d[\"_source\"]['id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR SEARCH Hit Rate is: 0.4540023894862604\n"
     ]
    }
   ],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "print(f\"VECTOR SEARCH Hit Rate is: {hit_rate(relevance_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR SEARCH  MRR is: 0.6554958183990423\n"
     ]
    }
   ],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "print(f\"VECTOR SEARCH  MRR is: {mrr(relevance_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_data = []\n",
    "for i in data:\n",
    "    d = {}\n",
    "    d['title'] = i['title']\n",
    "    d['text'] = i['text']\n",
    "    d['timecode_text'] = i['timecode_text']\n",
    "    d['description'] = i['description']\n",
    "    d['id'] = i['id']\n",
    "    d['title_vector'] = model.encode(i['title'])\n",
    "    d['timecode_vector'] = model.encode(i['timecode_text'])\n",
    "    d['text_vector'] = model.encode(i['text'])\n",
    "    d['description_vector'] = model.encode(i['description'])\n",
    "    hybrid_data.append(d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'hybrid-search'})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"timecode_text\": {\"type\": \"text\"},\n",
    "            \"description\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"title_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"timecode_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"description_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "index_name = \"hybrid-search\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in hybrid_data:\n",
    "    try:\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def knn_query(question, vector):\n",
    "    return  {\n",
    "        \"field\": f\"{vector}\",\n",
    "        \"query_vector\": model.encode(question),\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5,\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_query(question):\n",
    "    return {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": f\"{question}\",\n",
    "                    \"fields\": [\"description^3\", \"text\", \"title\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5,\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_search(key_word, vector):\n",
    "    response = es_client.search(\n",
    "        index=index_name,\n",
    "        query=keyword_query(key_word),\n",
    "        knn=knn_query(key_word, vector),\n",
    "        size=10\n",
    "    )\n",
    "    return response[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f2f63dd49a425e8a6d52874202aa45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Hit rate for title_vector is: 0.5543608124253285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c481a074608401a8ad779e3cc6eae13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Hit rate for timecode_vector is: 0.5639187574671446\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f2a4fffadb45319d149eb5ef0c4962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Hit rate for text_vector is: 0.5579450418160096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5055f3e9b44df1a20b9c060fa45181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Hit rate for description_vector is: 0.5519713261648745\n"
     ]
    }
   ],
   "source": [
    "for vector in ['title_vector','timecode_vector','text_vector','description_vector']:\n",
    "    from tqdm.auto import tqdm\n",
    "    relevance_total = []\n",
    "    for q in tqdm(data):\n",
    "        doc_id = q['id']\n",
    "        results = multi_search(q['student_question'], vector)\n",
    "        relevance = [d[\"_source\"]['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "        cnt = 0\n",
    "        for line in relevance_total:\n",
    "            if True in line:\n",
    "                cnt = cnt + 1\n",
    "\n",
    "    \n",
    "    print(f\"Hybrid Hit rate for {vector} is: {cnt / len(relevance_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f617b64053754f44bafefb6cf8630a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR is title_vector: 0.7265218751777894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c795a2d4eb340e28010b1185ec61ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR is timecode_vector: 0.7416993798714236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca7c167259b412cb119564ae4cd5f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR is text_vector: 0.737086818000797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5d1b5dbc394c99a1cf158398f9822c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR is description_vector: 0.7232325387343309\n"
     ]
    }
   ],
   "source": [
    "for vector in ['title_vector','timecode_vector','text_vector','description_vector']:\n",
    "    from tqdm.auto import tqdm\n",
    "    relevance_total = []\n",
    "    for q in tqdm(data):\n",
    "        doc_id = q['id']\n",
    "        results = multi_search(q['student_question'], vector)\n",
    "        relevance = [d[\"_source\"]['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "        total_score = 0.0\n",
    "        for line in relevance_total:\n",
    "            for rank in range(len(line)):\n",
    "                if line[rank] == True:\n",
    "                    total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "\n",
    "    print(f\"MRR is {vector}: {total_score / len(relevance_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate is: 0.5579450418160096\n"
     ]
    }
   ],
   "source": [
    "# def hit_rate(relevance_total):\n",
    "#     cnt = 0\n",
    "\n",
    "#     for line in relevance_total:\n",
    "#         if True in line:\n",
    "#             cnt = cnt + 1\n",
    "\n",
    "#     return cnt / len(relevance_total)\n",
    "# print(f\"Hybrid Hit rate is: {hit_rate(relevance_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR is: 0.737086818000797\n"
     ]
    }
   ],
   "source": [
    "# def mrr(relevance_total):\n",
    "#     total_score = 0.0\n",
    "\n",
    "#     for line in relevance_total:\n",
    "#         for rank in range(len(line)):\n",
    "#             if line[rank] == True:\n",
    "#                 total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "#     return total_score / len(relevance_total)\n",
    "# print(f\"MRR is: {mrr(relevance_total)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
