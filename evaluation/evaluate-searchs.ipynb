{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dependencies and read in Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gary/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-09-16 17:26:38.557828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-16 17:26:38.579490: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-16 17:26:38.579542: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-16 17:26:38.594018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-16 17:26:39.576384: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/gary/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "No CUDA runtime is found, using CUDA_HOME='/usr'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "with open('fixed_ground_truth.pkl','rb') as infile:\n",
    "    data = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model for Vector Search and connect to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)\n",
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create single text vector from title, the transcript text and the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data = []\n",
    "for i in data:\n",
    "    d = {}\n",
    "    d['title'] = i['title']\n",
    "    d['text'] = i['text']\n",
    "    d['timecode_text'] = i['timecode_text']\n",
    "    d['description'] = i['description']\n",
    "    d['id'] = i['id']\n",
    "    d['text_vector'] = model.encode(i['title']+' '+i['text']+' '+i['description'])\n",
    "    vector_data.append(d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the index for the single vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'vector-search'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"timecode_text\": {\"type\": \"text\"},\n",
    "            \"description\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "index_name = \"vector-search\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in vector_data:\n",
    "    try:\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_query(question):\n",
    "    return  {\n",
    "        \"field\": \"text_vector\",\n",
    "        \"query_vector\": model.encode(question),\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5,\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did we talk about Mage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(question):\n",
    "    res = es_client.search(index=index_name, knn=knn_query(question), source=[\"id\"])\n",
    "    return res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return results to calculate Hit Rate and MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf9f52d0d0d4323ab7da46c4af7e3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "relevance_total = []\n",
    "for q in tqdm(data):\n",
    "    doc_id = q['id']\n",
    "    results = vector_search(q['student_question'])\n",
    "    relevance = [d[\"_source\"]['id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR SEARCH Hit Rate is: 0.4540023894862604\n"
     ]
    }
   ],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "print(f\"VECTOR SEARCH Hit Rate is: {hit_rate(relevance_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR SEARCH  MRR is: 0.6554958183990423\n"
     ]
    }
   ],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "print(f\"VECTOR SEARCH  MRR is: {mrr(relevance_total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for hybrid search this time creating 4 vecors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_data = []\n",
    "for i in data:\n",
    "    d = {}\n",
    "    d['title'] = i['title']\n",
    "    d['text'] = i['text']\n",
    "    d['timecode_text'] = i['timecode_text']\n",
    "    d['description'] = i['description']\n",
    "    d['id'] = i['id']\n",
    "    d['title_vector'] = model.encode(i['title'])\n",
    "    d['timecode_vector'] = model.encode(i['timecode_text'])\n",
    "    d['text_vector'] = model.encode(i['text'])\n",
    "    d['description_vector'] = model.encode(i['description'])\n",
    "    hybrid_data.append(d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'hybrid-search'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"timecode_text\": {\"type\": \"text\"},\n",
    "            \"description\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"title_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"timecode_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"description_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "index_name = \"hybrid-search\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in hybrid_data:\n",
    "    try:\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def knn_query(question, vector):\n",
    "    return  {\n",
    "        \"field\": f\"{vector}\",\n",
    "        \"query_vector\": model.encode(question),\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5,\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_query(question):\n",
    "    return {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": f\"{question}\",\n",
    "                    \"fields\": [\"description^3\", \"text\", \"title\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5,\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_search(key_word, vector):\n",
    "    response = es_client.search(\n",
    "        index=index_name,\n",
    "        query=keyword_query(key_word),\n",
    "        knn=knn_query(key_word, vector),\n",
    "        size=10\n",
    "    )\n",
    "    return response[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Hybrid search, but also cycle through each vector and use it in the Hybrid Search to determine Hit Rate and MRR of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321761d3cfcd4425ac77baa0781731ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Hit rate for title_vector is: 0.5555555555555556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b01a68af7a4000844c48d24446d1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Hit rate for timecode_vector is: 0.5639187574671446\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595ad9bc1ffa4754bda59a0acf37c066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Hit rate for text_vector is: 0.5579450418160096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bafd7a17c84c489c9577ef9dc87b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Hit rate for description_vector is: 0.5531660692951016\n"
     ]
    }
   ],
   "source": [
    "for vector in ['title_vector','timecode_vector','text_vector','description_vector']:\n",
    "    from tqdm.auto import tqdm\n",
    "    relevance_total = []\n",
    "    for q in tqdm(data):\n",
    "        doc_id = q['id']\n",
    "        results = multi_search(q['student_question'], vector)\n",
    "        relevance = [d[\"_source\"]['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "        cnt = 0\n",
    "        for line in relevance_total:\n",
    "            if True in line:\n",
    "                cnt = cnt + 1\n",
    "\n",
    "    \n",
    "    print(f\"Hybrid Hit rate for {vector} is: {cnt / len(relevance_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172c045c82d14387967869ebf3193516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR is title_vector: 0.7258287345204912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf45e40b7a2b48de853fc5279b198f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR is timecode_vector: 0.7423180861352912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325eff4d57c84ebda59128d47f263155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR is text_vector: 0.737086818000797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb69823eabe146d28f118284f6959e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR is description_vector: 0.7257533519182269\n"
     ]
    }
   ],
   "source": [
    "for vector in ['title_vector','timecode_vector','text_vector','description_vector']:\n",
    "    from tqdm.auto import tqdm\n",
    "    relevance_total = []\n",
    "    for q in tqdm(data):\n",
    "        doc_id = q['id']\n",
    "        results = multi_search(q['student_question'], vector)\n",
    "        relevance = [d[\"_source\"]['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "        total_score = 0.0\n",
    "        for line in relevance_total:\n",
    "            for rank in range(len(line)):\n",
    "                if line[rank] == True:\n",
    "                    total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "\n",
    "    print(f\"MRR is {vector}: {total_score / len(relevance_total)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
