{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Load Dictionary\n",
    "with open('transcripts_timestamps_links.pkl', 'rb') as infile:\n",
    "    transcripts = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text_fragments(documents, chunk_size=3):\n",
    "    combined_docs = []\n",
    "    current_chunk = {\"Title\": documents[0]['Title'], \"Text\": \"\", \"TimeStamp\": documents[0]['TimeStamp']}\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        if i % chunk_size == 0 and i != 0:\n",
    "            combined_docs.append(current_chunk)\n",
    "            current_chunk = {\"Title\": doc['Title'], \"Text\": \"\", \"TimeStamp\": doc['TimeStamp'], \"Link\":doc['link']}\n",
    "        \n",
    "        current_chunk['Text'] += f\" {doc['Text']}\"\n",
    "    \n",
    "    combined_docs.append(current_chunk)\n",
    "    return combined_docs\n",
    "\n",
    "# Example usage\n",
    "documents = transcripts\n",
    "combined_documents = combine_text_fragments(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'llm zoomcamp 3.1 - introduction to vector search', 'Text': ' much more more optimized way and not only storage but you need to also think about how you can retrieve that', 'TimeStamp': 448.919, 'Link': 'https://www.youtube.com/watch?v=C5AWdL3kg1Q&t=448s'}\n",
      "{'Title': 'llm zoomcamp 3.3.4 - evaluating vector retrieval', 'Text': ' search average performance speed and model so i want the model with the best performance search uh but also i want to', 'TimeStamp': 119.039, 'Link': 'https://www.youtube.com/watch?v=VRprIm9-VV8&t=119s'}\n",
      "{'Title': 'llm zoomcamp 4.1 - introduction to monitoring answer quality', 'Text': \" compute there's not this one single metric that you can compute and then you know everything about your your rag or\", 'TimeStamp': 333.36, 'Link': 'https://www.youtube.com/watch?v=OWqinqemCmk&t=333s'}\n",
      "{'Title': 'llm zoomcamp 4.4 - offline rag evaluation: cosine similarity', 'Text': \" anyways so let us actually see uh how good we do on average so i'll use\", 'TimeStamp': 429.84, 'Link': 'https://www.youtube.com/watch?v=LlXclbD3pms&t=429s'}\n",
      "{'Title': 'llm zoomcamp - llm orchestration 5.0 module overview', 'Text': ' covering brag orchestration particularly the data preparation side where we ingest documents we transform them and', 'TimeStamp': 9.559, 'Link': 'https://www.youtube.com/watch?v=gP2ZOsG9Umg&t=9s'}\n",
      "{'Title': 'llm zoomcamp - llm orchestration 5.0 module overview', 'Text': ' the building experience so you that you can resume your work now in a rag pipeline there are two main pipelines', 'TimeStamp': 68.799, 'Link': 'https://www.youtube.com/watch?v=gP2ZOsG9Umg&t=68s'}\n",
      "{'Title': 'llm zoomcamp - llm orchestration 5.5 export', 'Text': \" your rag pipeline is to export the chunks and the embeddings into a vector database so let's go ahead\", 'TimeStamp': 5.4, 'Link': 'https://www.youtube.com/watch?v=cHrphSoRBX4&t=5s'}\n",
      "{'Title': 'llm zoomcamp - llm orchestration 5.6 retrieval', 'Text': ' our embeddings to a vector database we have completed creating the data preparation for a rag', 'TimeStamp': 4.88, 'Link': 'https://www.youtube.com/watch?v=z5NqDcaBglY&t=4s'}\n",
      "{'Title': 'llm zoomcamp - llm orchestration 5.6 retrieval', 'Text': \" we used now that we finished creating our data preparation for rag let's create a\", 'TimeStamp': 104.96, 'Link': 'https://www.youtube.com/watch?v=z5NqDcaBglY&t=104s'}\n",
      "{'Title': 'llm zoomcamp 6.1 - techniques to improve rag pipeline', 'Text': ' uh equal to an entire section maybe or the entire paragraph then um when when we will embed those chunks we will', 'TimeStamp': 317.72, 'Link': 'https://www.youtube.com/watch?v=Tq9Vbm_2z3o&t=317s'}\n",
      "{'Title': 'llm zoomcamp 6.1 - techniques to improve rag pipeline', 'Text': ' should use small chunks to put them in our storage to our database for example we can make embeddings of the single', 'TimeStamp': 372.199, 'Link': 'https://www.youtube.com/watch?v=Tq9Vbm_2z3o&t=372s'}\n",
      "{'Title': 'llm zoomcamp 6.1 - techniques to improve rag pipeline', 'Text': ' like moving on the second technique is uh called leveraging document', 'TimeStamp': 399.88, 'Link': 'https://www.youtube.com/watch?v=Tq9Vbm_2z3o&t=399s'}\n",
      "{'Title': 'llm zoomcamp 6.1 - techniques to improve rag pipeline', 'Text': ' leveraging the language model instead of a single language call we actually have two calls to the', 'TimeStamp': 709.839, 'Link': 'https://www.youtube.com/watch?v=Tq9Vbm_2z3o&t=709s'}\n"
     ]
    }
   ],
   "source": [
    "for i in combined_documents:\n",
    "    if 'rag' in i['Text']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
